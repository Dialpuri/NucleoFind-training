{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemmi \n",
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialise_neighbour_search(structure: gemmi.Structure, radius: int = 1.5):\n",
    "    sugar_neigbour_search = gemmi.NeighborSearch(structure[0], structure.cell, radius)\n",
    "    phosphate_neigbour_search = gemmi.NeighborSearch(\n",
    "        structure[0], structure.cell, radius\n",
    "    )\n",
    "    base_neigbour_search = gemmi.NeighborSearch(structure[0], structure.cell, radius)\n",
    "\n",
    "    sugar_atoms = [\"C1'\", \"C2'\", \"C3'\", \"C4'\", \"C5'\", \"O4'\"]\n",
    "    phosphate_atoms = [\"P\"] # [\"O5'\", \"P\", \"OP1\", \"OP2\"]\n",
    "    base_atoms = [\n",
    "        \"C1\", \"C2\", \"C3\", \"C4\", \"C5\",\"C6\", \"C7\", \"C8\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\", \"N9\", \"O2\", \"O4\", \"O6\"\n",
    "    ]\n",
    "\n",
    "    for n_ch, chain in enumerate(structure[0]):\n",
    "        for n_res, res in enumerate(chain):\n",
    "            for n_atom, atom in enumerate(res):\n",
    "                if atom.name in sugar_atoms:\n",
    "                    sugar_neigbour_search.add_atom(atom, n_ch, n_res, n_atom)\n",
    "                elif atom.name in phosphate_atoms:\n",
    "                    phosphate_neigbour_search.add_atom(atom, n_ch, n_res, n_atom)\n",
    "                elif atom.name in base_atoms:\n",
    "                    base_neigbour_search.add_atom(atom, n_ch, n_res, n_atom)\n",
    "\n",
    "    return (\n",
    "        sugar_neigbour_search,\n",
    "        phosphate_neigbour_search,\n",
    "        base_neigbour_search,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    # sugar_model = gemmi.Model(\"A\")\n",
    "    # phosphate_model = gemmi.Model(\"A\")\n",
    "    # base_model = gemmi.Model(\"A\")\n",
    "\n",
    "    # sugar_atoms = [\"C1'\", \"C2'\", \"C3'\", \"C4'\", \"C5'\", \"O4'\"]\n",
    "    # phosphate_atoms = [\"P\", \"OP1\", \"OP2\"]\n",
    "    # base_atoms = [\n",
    "    #     \"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"N7\", \"N8\", \"N9\", \"O2\", \"O4\", \"O6\"\n",
    "    # ]\n",
    "\n",
    "    # for c in st[0]: \n",
    "    #     sug_chain = gemmi.Chain(\"A\")\n",
    "    #     pho_chain = gemmi.Chain(\"A\")\n",
    "    #     bas_chain = gemmi.Chain(\"A\")\n",
    "\n",
    "    #     for r in c: \n",
    "    #         sug_r = r.clone()\n",
    "    #         pho_r = r.clone()\n",
    "    #         bas_r = r.clone()\n",
    "\n",
    "    #         k = gemmi.find_tabulated_residue(r.name)\n",
    "    #         for a in r:\n",
    "    #             if a.name not in sugar_atoms: \n",
    "    #                 sug_r.remove_atom(a.name, a.altloc, a.element)\n",
    "    #             if a.name not in phosphate_atoms: \n",
    "    #                 pho_r.remove_atom(a.name, a.altloc, a.element)\n",
    "    #             if a.name not in base_atoms: \n",
    "    #                 bas_r.remove_atom(a.name, a.altloc, a.element)\n",
    "\n",
    "    #         sug_chain.add_residue(sug_r)\n",
    "    #         pho_chain.add_residue(pho_r)\n",
    "    #         bas_chain.add_residue(bas_r)\n",
    "\n",
    "    #     sugar_model.add_chain(sug_chain)\n",
    "    #     phosphate_model.add_chain(pho_chain)\n",
    "    #     base_model.add_chain(bas_chain)\n",
    "        \n",
    "\n",
    "    # bases = os.path.join(output_dir, \"bases.pdb\")    \n",
    "    # bas_s = gemmi.Structure() \n",
    "    # bas_s.add_model(base_model)\n",
    "    # bas_s.cell = grid.unit_cell\n",
    "    # bas_s.write_pdb(bases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_map(array: gemmi.FloatGrid, path: str):\n",
    "    ccp4 = gemmi.Ccp4Map()\n",
    "    ccp4.grid = array\n",
    "    ccp4.update_ccp4_header()\n",
    "    ccp4.write_ccp4_map(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is a tuple of args -> mtz_path: str, pdb_path: str, pdb_code: str, output_dir: str, radius: float = 1.5\n",
    "def generate_maps(data):\n",
    "    mtz_path, pdb_path, pdb_code, output_dir, radius = data\n",
    "\n",
    "    if os.path.exists(output_dir): \n",
    "        return\n",
    "\n",
    "    mtz = gemmi.read_mtz_file(mtz_path)\n",
    "    st = gemmi.read_structure(pdb_path)\n",
    "\n",
    "    res = mtz.resolution_high()\n",
    "    spacing = 0.7\n",
    "    sample_rate = res/spacing\n",
    "    \n",
    "    grid = mtz.transform_f_phi_to_map(\"FWT\", \"PHWT\", sample_rate=sample_rate)\n",
    "    grid.normalize()\n",
    "\n",
    "    sugar_grid = grid.clone()\n",
    "    sugar_grid.fill(0)\n",
    "    phosphate_grid = grid.clone()\n",
    "    phosphate_grid.fill(0)\n",
    "    base_grid = grid.clone()\n",
    "    base_grid.fill(0)\n",
    "\n",
    "    sug, pho, bas = _initialise_neighbour_search(structure=st)\n",
    "    \n",
    "    for point in grid:\n",
    "        position = grid.point_to_position(point)\n",
    "        any_bases = bas.find_atoms(\n",
    "            position, \"\\0\", radius=radius\n",
    "        )\n",
    "        any_sugars = sug.find_atoms(\n",
    "            position, \"\\0\", radius=radius\n",
    "        )\n",
    "        any_phosphate = pho.find_atoms(\n",
    "            position, \"\\0\", radius=radius\n",
    "        )\n",
    "\n",
    "        base_mask = 1.0 if any_bases else 0.0\n",
    "        sugar_mask = 1.0 if any_sugars else 0.0\n",
    "        phosphate_mask = 1.0 if any_phosphate else 0.0\n",
    "\n",
    "        sugar_grid.set_value(point.u, point.v, point.w, sugar_mask)\n",
    "        phosphate_grid.set_value(point.u, point.v, point.w, phosphate_mask)\n",
    "        base_grid.set_value(point.u, point.v, point.w, base_mask)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    save_map(sugar_grid, os.path.join(output_dir, \"sugar.map\"))\n",
    "    save_map(phosphate_grid, os.path.join(output_dir, \"phosphate.map\"))\n",
    "    save_map(base_grid, os.path.join(output_dir, \"base.map\"))\n",
    "    save_map(grid, os.path.join(output_dir, \"experimental.map\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captured_worker(data):\n",
    "    try: \n",
    "        generate_maps(data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"na_only\"\n",
    "df = pd.read_csv(f\"/vault/NucleoFind-training-pr/data/{type}/refined_paths.csv\")\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "radius = 1.5\n",
    "train_data = [(mtz_path, pdb_path, pdb, f\"/vault/NucleoFind-training-pr/train_maps/{type}/{pdb}\", radius) for index, (pdb, mtz_path, pdb_path) in train.iterrows()]\n",
    "test_data = [(mtz_path, pdb_path, pdb,f\"/vault/NucleoFind-training-pr/test_maps/{type}/{pdb}\", radius) for index, (pdb, mtz_path, pdb_path) in test.iterrows()]\n",
    "\n",
    "\n",
    "# with multiprocessing.Pool(8) as p:\n",
    "#     x = list(tqdm(\n",
    "#         p.imap_unordered(captured_worker, train_data), total=len(train_data)\n",
    "#     ))\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    x = list(tqdm(\n",
    "        p.imap_unordered(captured_worker, test_data), total=len(test_data)\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"protein_na\"\n",
    "df = pd.read_csv(f\"/vault/NucleoFind-training-pr/data/{type}/refined_paths.csv\")\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "radius = 1.5\n",
    "ref_train_data = [(mtz_path, pdb_path, pdb, f\"/vault/NucleoFind-training-pr/train_maps/{type}/{pdb}\", radius) for index, (pdb, mtz_path, pdb_path) in train.iterrows()]\n",
    "ref_test_data = [(mtz_path, pdb_path, pdb,f\"/vault/NucleoFind-training-pr/test_maps/{type}/{pdb}\", radius) for index, (pdb, mtz_path, pdb_path) in test.iterrows()]\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    x = list(tqdm(\n",
    "        p.imap_unordered(captured_worker, ref_train_data), total=len(ref_train_data)\n",
    "    ))\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    x = list(tqdm(\n",
    "        p.imap_unordered(captured_worker, ref_test_data), total=len(ref_test_data)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 47/4944 [02:57<5:07:49,  3.77s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py:848\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    849\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m         unref_train_data\u001b[39m.\u001b[39mappend((data_dir, row[\u001b[39m\"\u001b[39m\u001b[39mPDBPath\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m], pdb,  \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/vault/NucleoFind-training-pr/test_maps/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mpdb\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, radius))\n\u001b[1;32m     24\u001b[0m \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mPool(\u001b[39m8\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m---> 25\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(tqdm(\n\u001b[1;32m     26\u001b[0m         p\u001b[39m.\u001b[39;49mimap_unordered(captured_worker, unref_train_data), total\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(unref_train_data)\n\u001b[1;32m     27\u001b[0m     ))\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m multiprocessing\u001b[39m.\u001b[39mPool(\u001b[39m8\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m     30\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tqdm(\n\u001b[1;32m     31\u001b[0m         p\u001b[39m.\u001b[39mimap_unordered(captured_worker, unref_test_data), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(unref_test_data)\n\u001b[1;32m     32\u001b[0m     ))\n",
      "File \u001b[0;32m/vault/NucleoFind-training-pr/.venv/lib/python3.8/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    852\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    854\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/miniconda3/envs/test/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"/vault/NucleoFind-training-pr/data/protein_na/refined_paths.csv\")\n",
    "radius = 1.5\n",
    "\n",
    "type=\"protein_na_unref_none\"\n",
    "unref_train_data = []\n",
    "\n",
    "for path in os.scandir(\"/vault/NucleoFind-training-pr/train_maps/protein_na\"):\n",
    "    pdb = path.name\n",
    "    row = df[df[\"PDB\"]==pdb]\n",
    "    unrefined_base_path = \"/vault/NucleoFind-training-pr/unrefined_data_b\"\n",
    "    data_dir = os.path.join(unrefined_base_path, pdb, \"0\", f\"{pdb}_0.mtz\")\n",
    "    if os.path.exists(data_dir):\n",
    "        unref_train_data.append((data_dir, row[\"PDBPath\"].values[0], pdb,  f\"/vault/NucleoFind-training-pr/train_maps/{type}/{pdb}\", radius))\n",
    "\n",
    "unref_test_data = []\n",
    "for path in os.scandir(\"/vault/NucleoFind-training-pr/test_maps/protein_na\"):\n",
    "    pdb = path.name\n",
    "    row = df[df[\"PDB\"]==pdb]\n",
    "    unrefined_base_path = \"/vault/NucleoFind-training-pr/unrefined_data_b\"\n",
    "    data_dir = os.path.join(unrefined_base_path, pdb, \"0\", f\"{pdb}_0.mtz\")\n",
    "    if os.path.exists(data_dir):\n",
    "        unref_train_data.append((data_dir, row[\"PDBPath\"].values[0], pdb,  f\"/vault/NucleoFind-training-pr/test_maps/{type}/{pdb}\", radius))\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    x = list(tqdm(\n",
    "        p.imap_unordered(captured_worker, unref_train_data), total=len(unref_train_data)\n",
    "    ))\n",
    "\n",
    "with multiprocessing.Pool(8) as p:\n",
    "    x = list(tqdm(\n",
    "        p.imap_unordered(captured_worker, unref_test_data), total=len(unref_test_data)\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
